\newpage
# Results
<!--  Descripció i anàlisis dels resultats obtinguts amb la metodologia proposada -->
Describe results and analyze them. Make sure to include pretty graphs whenever possible. Everybody loves pretty pictures.

## Reproduction

### Results of kNN
<!--  TODO: make figure/table references actual links to the referencee -->

There are two different values we can set to tweak the behavior of the k-NN classifier: one is *k*, the number of neighbors that the algorithm will take into account for each point. The other doesn't actually belong to the classifier itself, but rather is about the shape of the data we provide it: the number of Principal Components of the data we feed it.

Much like @vidal_structural_2020 we choose choose three numbers of Principal Components: ones that explain 85, 90 and 95% of variance; then we run the classifier using a range of numbers of neighbors between 1 and 500. This sort of sweep lets us judge its performance for several combinations of parameters such that we can hone in on a sensible.

**TODO: Talk about how this brute-force approach is generally best when approaching a new problem using ML, as the "ideal" parameter values can vary wildly depending on characteristics of the data that we can't really determine beforehand. Make sure to cite relevant works.**

The results for all these permutations are displayed in [@tbl:reproduce-results-table-knn] **TODO: talk about them and compare to the results from @vidal_structural_2020**

**TODO: don't repeat variance/pc_num values in all rows**

+------------+----------+-----+--------+--------+--------+--------+--------+
|   variance |   pc_num |   k |    acc |    ppv |    tpr |     f1 |    tnr |
+============+==========+=====+========+========+========+========+========+
|        85% |      580 |   1 | 93.75% | 84.78% | 84.38% | 84.58% | 95.82% |
+------------+----------+-----+--------+--------+--------+--------+--------+
|        85% |      580 |   5 | 94.47% | 87.91% | 83.39% | 85.59% | 95.85% |
+------------+----------+-----+--------+--------+--------+--------+--------+
|        85% |      580 |  10 | 93.87% | 87.89% | 80.84% | 84.22% | 95.21% |
+------------+----------+-----+--------+--------+--------+--------+--------+
|        85% |      580 |  25 | 94.06% | 89.31% | 79.95% | 84.37% | 95.28% |
+------------+----------+-----+--------+--------+--------+--------+--------+
|        85% |      580 |  50 | 96.22% | 92.01% | 87.11% | 89.49% | 97.30% |
+------------+----------+-----+--------+--------+--------+--------+--------+
|        85% |      580 | 100 | 97.87% | 94.81% | 92.59% | 93.69% | 98.60% |
+------------+----------+-----+--------+--------+--------+--------+--------+
|        85% |      580 | 150 | 97.14% | 92.44% | 90.07% | 91.24% | 98.21% |
+------------+----------+-----+--------+--------+--------+--------+--------+
|        85% |      580 | 200 | 96.82% | 91.81% | 88.90% | 90.33% | 97.97% |
+------------+----------+-----+--------+--------+--------+--------+--------+
|        85% |      580 | 250 | 96.24% | 90.80% | 86.88% | 88.80% | 97.49% |
+------------+----------+-----+--------+--------+--------+--------+--------+
|        85% |      580 | 300 | 95.02% | 88.72% | 82.65% | 85.57% | 96.51% |
+------------+----------+-----+--------+--------+--------+--------+--------+
|        85% |      580 | 500 | 86.95% | 77.73% | 54.42% | 64.01% | 89.40% |
+------------+----------+-----+--------+--------+--------+--------+--------+
|        90% |     1034 |   1 | 93.80% | 85.03% | 85.35% | 85.19% | 95.99% |
+------------+----------+-----+--------+--------+--------+--------+--------+
|        90% |     1034 |   5 | 94.08% | 86.60% | 83.39% | 84.96% | 95.70% |
+------------+----------+-----+--------+--------+--------+--------+--------+
|        90% |     1034 |  10 | 93.60% | 85.28% | 81.25% | 83.22% | 95.33% |
+------------+----------+-----+--------+--------+--------+--------+--------+
|        90% |     1034 |  25 | 94.71% | 89.20% | 82.61% | 85.78% | 96.00% |
+------------+----------+-----+--------+--------+--------+--------+--------+
|        90% |     1034 |  50 | 96.43% | 92.23% | 87.85% | 89.98% | 97.55% |
+------------+----------+-----+--------+--------+--------+--------+--------+
|        90% |     1034 | 100 | 98.08% | 95.12% | 93.33% | 94.22% | 98.78% |
+------------+----------+-----+--------+--------+--------+--------+--------+
|        90% |     1034 | 150 | 97.23% | 92.62% | 90.37% | 91.48% | 98.28% |
+------------+----------+-----+--------+--------+--------+--------+--------+
|        90% |     1034 | 200 | 96.73% | 91.63% | 88.60% | 90.09% | 97.92% |
+------------+----------+-----+--------+--------+--------+--------+--------+
|        90% |     1034 | 250 | 96.06% | 90.42% | 86.26% | 88.29% | 97.39% |
+------------+----------+-----+--------+--------+--------+--------+--------+
|        90% |     1034 | 300 | 94.98% | 88.67% | 82.50% | 85.47% | 96.49% |
+------------+----------+-----+--------+--------+--------+--------+--------+
|        90% |     1034 | 500 | 86.98% | 77.90% | 54.51% | 64.13% | 89.43% |
+------------+----------+-----+--------+--------+--------+--------+--------+
|        95% |     1985 |   1 | 93.66% | 84.57% | 85.22% | 84.89% | 95.90% |
+------------+----------+-----+--------+--------+--------+--------+--------+
|        95% |     1985 |   5 | 93.80% | 85.54% | 83.03% | 84.27% | 95.59% |
+------------+----------+-----+--------+--------+--------+--------+--------+
|        95% |     1985 |  10 | 93.61% | 84.94% | 81.76% | 83.32% | 95.43% |
+------------+----------+-----+--------+--------+--------+--------+--------+
|        95% |     1985 |  25 | 94.92% | 89.35% | 83.51% | 86.33% | 96.22% |
+------------+----------+-----+--------+--------+--------+--------+--------+
|        95% |     1985 |  50 | 96.61% | 92.38% | 88.49% | 90.39% | 97.76% |
+------------+----------+-----+--------+--------+--------+--------+--------+
|        95% |     1985 | 100 | 98.17% | 95.27% | 93.66% | 94.46% | 98.85% |
+------------+----------+-----+--------+--------+--------+--------+--------+
|        95% |     1985 | 150 | 97.31% | 92.81% | 90.65% | 91.72% | 98.34% |
+------------+----------+-----+--------+--------+--------+--------+--------+
|        95% |     1985 | 200 | 96.79% | 91.72% | 88.79% | 90.23% | 97.97% |
+------------+----------+-----+--------+--------+--------+--------+--------+
|        95% |     1985 | 250 | 96.22% | 90.72% | 86.82% | 88.72% | 97.53% |
+------------+----------+-----+--------+--------+--------+--------+--------+
|        95% |     1985 | 300 | 95.14% | 89.01% | 83.05% | 85.92% | 96.62% |
+------------+----------+-----+--------+--------+--------+--------+--------+
|        95% |     1985 | 500 | 87.11% | 78.28% | 54.97% | 64.57% | 89.55% |
+------------+----------+-----+--------+--------+--------+--------+--------+

: Performance indicators for the k-NN classifier using principal components that explain 85, 90 and 95% of variance. {#tbl:reproduce-results-table-knn}

The performance indicators for the k-NN classifier using principal components that explain 90% of variance are displayed in [@fig:reproduce-indicators-plot-knn-var0.9]. We can see that the best results are obtained with k=100. This differs from the values reached because the shape of our data set is slightly different: whereas **(TODO: explain this comparing both datasets. number and length of trials)**

![Indicators evaluating the performance of the k-NN method using 90% of variance. Higher values are better.](reproduce-indicators-plot-knn-var0.9.png){#fig:reproduce-indicators-plot-knn-var0.9 width=80%}

### Results of SVM

+------------+----------+-----+--------+--------+--------+--------+--------+
|   variance |   pc_num |   ρ |    acc |    ppv |    tpr |     f1 |    tnr |
+============+==========+=====+========+========+========+========+========+
|        85% |      580 |   5 | 99.92% | 99.85% | 99.73% | 99.79% | 99.93% |
+------------+----------+-----+--------+--------+--------+--------+--------+
|        85% |      580 |  20 | 99.92% | 99.85% | 99.73% | 99.79% | 99.93% |
+------------+----------+-----+--------+--------+--------+--------+--------+
|        85% |      580 |  30 | 99.93% | 99.90% | 99.78% | 99.84% | 99.94% |
+------------+----------+-----+--------+--------+--------+--------+--------+
|        85% |      580 |  40 | 99.94% | 99.93% | 99.81% | 99.87% | 99.95% |
+------------+----------+-----+--------+--------+--------+--------+--------+
|        85% |      580 |  50 | 99.07% | 97.34% | 96.71% | 97.02% | 99.44% |
+------------+----------+-----+--------+--------+--------+--------+--------+
|        85% |      580 |  60 | 97.69% | 94.30% | 91.95% | 93.11% | 98.63% |
+------------+----------+-----+--------+--------+--------+--------+--------+
|        85% |      580 |  70 | 97.08% | 93.36% | 89.81% | 91.55% | 98.22% |
+------------+----------+-----+--------+--------+--------+--------+--------+
|        85% |      580 |  80 | 95.30% | 95.08% | 83.59% | 88.95% | 95.94% |
+------------+----------+-----+--------+--------+--------+--------+--------+
|        85% |      580 |  90 | 93.64% | 94.59% | 77.77% | 85.35% | 94.44% |
+------------+----------+-----+--------+--------+--------+--------+--------+
|        85% |      580 | 100 | 92.24% | 93.78% | 72.88% | 82.00% | 93.22% |
+------------+----------+-----+--------+--------+--------+--------+--------+
|        85% |      580 | 150 | 86.66% | 91.25% | 53.33% | 67.31% | 88.33% |
+------------+----------+-----+--------+--------+--------+--------+--------+
|        85% |      580 | 200 | 83.95% |   nan% | 43.88% |   nan% | 85.96% |
+------------+----------+-----+--------+--------+--------+--------+--------+
|        85% |      580 | 300 | 79.96% |   nan% | 29.82% |   nan% | 82.46% |
+------------+----------+-----+--------+--------+--------+--------+--------+
|        90% |     1034 |   5 | 99.87% | 99.84% | 99.58% | 99.71% | 99.89% |
+------------+----------+-----+--------+--------+--------+--------+--------+
|        90% |     1034 |  20 | 99.87% | 99.84% | 99.58% | 99.71% | 99.89% |
+------------+----------+-----+--------+--------+--------+--------+--------+
|        90% |     1034 |  30 | 99.87% | 99.84% | 99.58% | 99.71% | 99.89% |
+------------+----------+-----+--------+--------+--------+--------+--------+
|        90% |     1034 |  40 | 99.88% | 99.86% | 99.59% | 99.73% | 99.90% |
+------------+----------+-----+--------+--------+--------+--------+--------+
|        90% |     1034 |  50 | 99.37% | 98.24% | 97.75% | 97.99% | 99.60% |
+------------+----------+-----+--------+--------+--------+--------+--------+
|        90% |     1034 |  60 | 97.79% | 94.54% | 92.29% | 93.40% | 98.68% |
+------------+----------+-----+--------+--------+--------+--------+--------+
|        90% |     1034 |  70 | 97.02% | 93.29% | 89.59% | 91.41% | 98.17% |
+------------+----------+-----+--------+--------+--------+--------+--------+
|        90% |     1034 |  80 | 95.02% | 95.49% | 82.64% | 88.58% | 95.66% |
+------------+----------+-----+--------+--------+--------+--------+--------+
|        90% |     1034 |  90 | 93.57% | 94.55% | 77.55% | 85.20% | 94.38% |
+------------+----------+-----+--------+--------+--------+--------+--------+
|        90% |     1034 | 100 | 92.60% | 93.98% | 74.11% | 82.86% | 93.53% |
+------------+----------+-----+--------+--------+--------+--------+--------+
|        90% |     1034 | 150 | 86.67% | 91.25% | 53.37% | 67.35% | 88.34% |
+------------+----------+-----+--------+--------+--------+--------+--------+
|        90% |     1034 | 200 | 84.00% |   nan% | 44.05% |   nan% | 86.00% |
+------------+----------+-----+--------+--------+--------+--------+--------+
|        90% |     1034 | 300 | 79.96% |   nan% | 29.82% |   nan% | 82.46% |
+------------+----------+-----+--------+--------+--------+--------+--------+
|        95% |     1985 |   5 | 99.84% | 99.80% | 99.46% | 99.63% | 99.86% |
+------------+----------+-----+--------+--------+--------+--------+--------+
|        95% |     1985 |  20 | 99.84% | 99.80% | 99.46% | 99.63% | 99.86% |
+------------+----------+-----+--------+--------+--------+--------+--------+
|        95% |     1985 |  30 | 99.84% | 99.80% | 99.46% | 99.63% | 99.86% |
+------------+----------+-----+--------+--------+--------+--------+--------+
|        95% |     1985 |  40 | 99.84% | 99.80% | 99.46% | 99.63% | 99.86% |
+------------+----------+-----+--------+--------+--------+--------+--------+
|        95% |     1985 |  50 | 99.74% | 99.45% | 99.07% | 99.26% | 99.80% |
+------------+----------+-----+--------+--------+--------+--------+--------+
|        95% |     1985 |  60 | 98.09% | 95.14% | 93.32% | 94.22% | 98.84% |
+------------+----------+-----+--------+--------+--------+--------+--------+
|        95% |     1985 |  70 | 96.99% | 93.21% | 89.47% | 91.30% | 98.17% |
+------------+----------+-----+--------+--------+--------+--------+--------+
|        95% |     1985 |  80 | 95.12% | 95.58% | 82.97% | 88.82% | 95.74% |
+------------+----------+-----+--------+--------+--------+--------+--------+
|        95% |     1985 |  90 | 93.51% | 94.51% | 77.33% | 85.05% | 94.33% |
+------------+----------+-----+--------+--------+--------+--------+--------+
|        95% |     1985 | 100 | 92.59% | 93.97% | 74.06% | 82.82% | 93.52% |
+------------+----------+-----+--------+--------+--------+--------+--------+
|        95% |     1985 | 150 | 86.64% | 91.24% | 53.28% | 67.27% | 88.31% |
+------------+----------+-----+--------+--------+--------+--------+--------+
|        95% |     1985 | 200 | 83.99% |   nan% | 44.02% |   nan% | 86.00% |
+------------+----------+-----+--------+--------+--------+--------+--------+
|        95% |     1985 | 300 | 79.95% |   nan% | 29.80% |   nan% | 82.46% |
+------------+----------+-----+--------+--------+--------+--------+--------+

: Performance indicators for the SVM classifier using principal components that explain 85, 90 and 95% of variance. **(TODO: figure out where the NaNs are coming from. probably terrible results for that ρ leading to division by zero when computing those indicators)** {#tbl:reproduce-results-table-svm}


![Indicators evaluating the performance of the SVM method using 85% of variance. Higher values are better.](reproduce-indicators-plot-svm-var0.85.png){#fig:reproduce-indicators-plot-svm-var0.85 width=80%}

## Proposed improvements

### Results of additional classifier(s)
bad

### Results of scaling and dimensionality reduction on the training set only
*shrug*
